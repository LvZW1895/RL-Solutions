# 第四章 动态规划 习题解答

**例 4.1** 考虑下方的一个$4×4$的网络图。

<img src="img/pic4-1.png" alt="图片4-1" style="zoom: 50%;" />

非终止状态集合$S = {\{1, 2, ..., 14\}}$。每个状态有四种可能的动作，$A = {up,down,right,left}$。每个动作会导致状态转移，但当动作会导致智能体移出网络时，状态保持不变。比如，$p(6, -1|5,right)=1$，$p(7,-1|7,right)=1$和对于任意$r\in{R}$，都有$p(10,r|5,right)=0$。这是一个无折扣的分幕式任务。在到达终止状态之前，所有动作的收益均为$-1$。终止状态在图中以阴影显示（尽管图中显示了两个格子，但实际仅有一个终止状态）。对于所有的状态$s,s'$与动作$a$，期望的收益函数均为$r(s,a,s')=-1$。假设智能体采取等概率随机策略（所有动作等可能执行）。下图（左）显示了在迭代策略评估中价值序列$\{v_k\}$的收敛情况。最终的近似估计实际上就是$v_{\pi}$，其值为每个状态到终止状态的步数的期望值，取负。

<img src="img/pic4-2.png" alt="图片4-2" style="zoom:67%;" />

## 练习4.1

> 在例4.1中，如果$\pi$是等概率随机策略，那么$q_{\pi}(11,down)$是多少？$q_{\pi}(7,down)$呢？

题目分析：由于上例说明这是一个无折扣的分幕式任务，因此在下面的问题当中$\gamma = 1$。另外，特别地，我们将阴影部分的终止状态用$T$来表示。

*解答：*在练习3.13中，我们已经推导出了如何用$v_{\pi}$和四参数函数$p$表达$q_{\pi}$公式：
$$
q_{\pi}(s,a)=\sum_{s',r}p(s',r|s,a)[r + \gamma v_{\pi}(s')]
$$
因此在第一个问题中：（由上图$v_{\pi}$收敛后的图表查出$v_{\pi}(T) = 0$）
$$
q_{\pi}(11,down) = p(T, -1|11,down)[-1 + \gamma v_{\pi}(T)] = 1 * [-1 + 1 * 0] = -1
$$
在第二个问题中：（由上图$v_{\pi}$收敛后的图表查出$v_{\pi}(11) = -14$）
$$
q_{\pi}(7, down) = p(11, -1|7, down)[-1 + \gamma v_{\pi}(11)] = 1 * [-1 + 1 * -14] = -15
$$

## 练习4.2

> 在例4.1中，假设一个新状态15加入到状态13的下方。从状态15开始，采取策略$left、up、right$和$down$，分别到达状态12、13、14和15。假设从原来的状态转出的方式不变，那么$v_{\pi}(15)$在等概率随机策略下是多少？如果状态13的动态特性产生变化，使得采取动作$down$时会到达这个新状态15，这时候的$v_{\pi}(15)$在等概率随机策略下是多少？

*解答：*（1）假设从原来的状态转出的方式不变，这意味着新添加的新状态“15”，对原本其它位置的状态价值函数值不影响，保持不变。我们可以根据书中式4.4计算新状态“15”的状态价值函数：
$$
式4.4：\ v_{\pi}(s) = \sum_{a}\pi(a|s)\sum_{s',r}p(s',r|s,a)[r + \gamma v_{\pi}(s')] \\
\begin{align}
v_{\pi}(15) = \pi(left|15)p(12, -1|15,left)[-1 + 1 * v_{\pi}(12)] \\
+ \pi(up|15)p(13, -1|15,up)[-1 + 1 * v_{\pi}(13)] \\
+ \pi(right|15)p(14, -1|15,right)[-1 + 1 * v_{\pi}(14)] \\
+ \pi(down|15)p(15, -1|15,down)[-1 + 1 * v_{\pi}(15)]
\end{align}
$$
由上图$v_{\pi}$收敛后的图表查出$v_{\pi}(12) = -22$，$v_{\pi}(13) = -20$，$v_{\pi}(14) = -14$,又由于是等概率随机策略,所以$\pi(left|15),\pi(up|15),\pi(right|15),\pi(down|15)$均为$\frac{1}{4}$带入上式化简得：
$$
v_{\pi}(15) = \frac{1}{4}*[-23-21-15-1+v_{\pi}(15)]\\
解得:v_{\pi}(15) = -20
$$
（2）如果状态13的动态特性产生变化，使得采取动作$down$时会到达这个新状态15：

我们需要使用式4.4列出$v_{\pi}(13)$以及$v_{\pi}(15)$的方程组求解，与上一小问类似，带入各值后：
$$
v_{\pi}(13) = \frac{1}{4}\{ [-1 + v_{\pi}(12)] + [-1 + v_{\pi}(9)] + [-1 + v_{\pi}(14)] + [-1 + v_{\pi}(15)]\} \\
v_{\pi}(15) = \frac{1}{4}\{ [-1 + v_{\pi}(12)] + [-1 + v_{\pi}(13)] + [-1 + v_{\pi}(14)] + [-1 + v_{\pi}(15)]\} \\
$$
同样从上图查表化简后，带入$v_{\pi}(12) = -22$，$v_{\pi}(14) = -14$，$v_{\pi}(9) = -20$解得：
$$
v_{\pi}(13) = v_{\pi}(15) = -20
$$
因此结论与第一问一致$v_{\pi}(15) = -20$。

## 练习4.3

> 对于动作价值函数$q_{\pi}$以及其逼近序列函数$q_0, q_1, q_2,...$，类似于式（4.3）、式（4.4）和式（4.5）的公式是什么？

*解答：*类似于式（4.3）、式（4.4）的公式为动作价值函数$q_{\pi}(s, a)$的贝尔曼方程：
$$
\begin{align}
q_{\pi}(s, a) &= \mathbb{E}[G_t|S_t = s, A_t = a] \\
&=\mathbb{E}_{\pi}[R_{t + 1}|S_t = s, A_t = a] + \gamma \mathbb{E}_{\pi}[G_{t + 1|S_t = s, A_t = a}] \\
&=\sum_{s',r}p(s',r|s,a)[r + \gamma \sum_{a'}\pi(a'|s')q_{\pi}(s',a')]
\end{align}
$$
迭代法求近似的动作价值函数，类似于式（4.5）的公式：
$$
q_{k + 1}(s, a) = \sum_{s',r}p(s',r|s,a)[r + \gamma \sum_{a'}\pi(a'|s')q_{k}(s',a')]
$$


